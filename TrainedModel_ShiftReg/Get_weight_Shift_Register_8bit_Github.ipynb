{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surajitdas2030/ML-Based-Output-Prediction-of-RTL-Model/blob/main/TrainedModel_ShiftReg/Get_weight_Shift_Register_8bit_Github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "smVZu0ZkDIVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb12bb3b-5451-47e0-d313-2e5e46d912dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "# only for Google Colab compatibiity\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0qfLj-yKG04w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "646b2a78-73e5-4968-8751-c948558e62ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, activations\n",
        "import random\n",
        "print(tf.__version__)\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "e53-4_dhOvc7"
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5c6XTFaMAf-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf2e37a-2afe-47a1-8248-7b24d0b7aa8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('shift.txt',sep=\" \",header=None)\n",
        "col_str_dic = {column:str for column in list(df)}\n",
        "df = pd.read_csv(\"shift.txt\",sep=\" \",header=None, dtype=col_str_dic)\n",
        "x_clk = df.iloc[:,0]\n",
        "x_bit = df.iloc[:,1]\n",
        "y_gen = df.iloc[:,2]\n",
        "x_samples=[]\n",
        "y_samples=[]\n",
        "k = 0\n",
        "for x in x_bit:\n",
        "  k = k+1\n",
        "\n",
        "temp = list(x_clk[0])\n",
        "temp_list=[]\n",
        "for c in temp:\n",
        "  temp_list.append(int(c))\n",
        "temp = list(x_bit[0])\n",
        "for c in temp:\n",
        "  temp_list.append(int(c))\n",
        "temp = list(y_gen[0])\n",
        "for c in temp:\n",
        "  temp_list.append(int(c))\n",
        "x_samples.append(temp_list)\n",
        "\n",
        "for i in range(1,k):\n",
        "  temp = list(x_clk[i])\n",
        "  temp_list=[]\n",
        "  for c in temp:\n",
        "    temp_list.append(int(c))\n",
        "  temp = list(x_bit[i])\n",
        "  for c in temp:\n",
        "    temp_list.append(int(c))\n",
        "  temp = list(y_gen[i-1])\n",
        "  for c in temp:\n",
        "    temp_list.append(int(c))\n",
        "  x_samples.append(temp_list)\n",
        "\n",
        "\n",
        "for y in y_gen:\n",
        "  # print(y)\n",
        "  temp = list(y)\n",
        "  temp_list=[]\n",
        "  for c in temp:\n",
        "    temp_list.append(int(c))\n",
        "  y_samples.append(temp_list)\n",
        "\n",
        "print(x_samples[2])\n",
        "print(y_samples[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT3ZM-S6Afz0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "69M8fzA9Me2k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29cd5f03-dc20-46d9-b537-8d8ad019700d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "x_s = []\n",
        "y_s = []\n",
        "# k = len(x_samples)\n",
        "# temp =[]\n",
        "# temp.append(x_samples[0])\n",
        "# temp.append(x_samples[0])\n",
        "# x_s.append(temp)\n",
        "# for i in range(1,k):\n",
        "#   temp = []\n",
        "#   temp.append(y_samples[i-1])\n",
        "#   temp.append(x_samples[i])\n",
        "#   x_s.append(temp)\n",
        "y_s = y_samples\n",
        "x_s = x_samples\n",
        "print(x_s[2])\n",
        "print(y_s[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "e9DxNbchB-S6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b763ed-61a5-42ce-f6f3-45eb1af136a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10421"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(y_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_cDMI7Y0G6U_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb72beda-d747-4e11-8cc4-32070f2c5ee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 0 0 0 0 0 0 0]\n",
            "[1 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "x_temp = np.array(x_s) # 16 inputs\n",
        "x_t = []\n",
        "for a in x_temp:\n",
        "  temp = a.flatten()\n",
        "  x_t.append(temp)\n",
        "x = np.array(x_t)\n",
        "print(x[2])\n",
        "y_temp = np.array(y_s) # 16 inputs\n",
        "y_t = []\n",
        "for a in y_temp:\n",
        "  temp = a.flatten()\n",
        "  y_t.append(temp)\n",
        "y = np.array(y_t)\n",
        "print(y[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4yvp6BOQRoGP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True)\n",
        "#x_train, x_test, y_train, y_test = train_test_split(x_samples, y_samples, test_size=0.3, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ArLM-bGjP34l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1caf8e-cdd4-4041-fdaa-3a93e5b8a5a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 8)                 88        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 308\n",
            "Trainable params: 308\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "layers=3\n",
        "inputs=10\n",
        "neurons_l0=10\n",
        "neurons_l1=10\n",
        "neurons_l2=8\n",
        "\n",
        "# ANN3:0.99 accuracy\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(10, input_dim=10, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(8, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "x23CuX8Kk8b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "099db2f4-b3fa-40df-dcb1-2b3c8eed7328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight1\n",
            "[array([[-0.15436366, -0.11579472, -0.46121883, -0.5341646 , -0.533273  ,\n",
            "         0.32213116, -0.0159443 ,  0.11680561, -0.15469638, -0.13228828],\n",
            "       [-0.05351323,  0.2950412 ,  0.09340656,  0.46987367, -0.02976435,\n",
            "        -0.4080215 ,  0.5203922 ,  0.19622368,  0.26016462,  0.18883252],\n",
            "       [-0.54599845,  0.20735258,  0.02260256, -0.5439447 , -0.42998526,\n",
            "         0.5241455 , -0.47153705, -0.32724157,  0.5261698 , -0.03738832],\n",
            "       [ 0.17259753,  0.44076276,  0.3532527 , -0.4179937 ,  0.28868318,\n",
            "         0.25607306, -0.22589687,  0.33387524, -0.40996426,  0.17921752],\n",
            "       [-0.14130637,  0.31612295, -0.35564756, -0.06175289, -0.41843298,\n",
            "         0.20139867,  0.4085192 , -0.01769614, -0.21693778, -0.4708913 ],\n",
            "       [ 0.22381568,  0.5014857 , -0.5170348 , -0.515724  , -0.27558726,\n",
            "         0.36676484, -0.51898307,  0.08665037, -0.47776243,  0.13622731],\n",
            "       [ 0.53868103,  0.27408862, -0.23386645, -0.02296805,  0.01346785,\n",
            "         0.29991096,  0.49165177,  0.02571887, -0.00816643,  0.22753954],\n",
            "       [ 0.29415756, -0.12013191,  0.03416944, -0.32424992, -0.5032913 ,\n",
            "        -0.5233298 ,  0.20182651,  0.38545698,  0.4884907 , -0.4436405 ],\n",
            "       [-0.42210928,  0.44268864, -0.48356348, -0.24137995,  0.42320347,\n",
            "        -0.47172105,  0.18760371, -0.44980618,  0.4822427 ,  0.52789533],\n",
            "       [-0.39992487, -0.15061462, -0.20227167, -0.12449038,  0.47876668,\n",
            "        -0.5198328 ,  0.46829283,  0.03500235,  0.29269117, -0.5460047 ]],\n",
            "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([[-0.3711365 ,  0.14483953, -0.32205766,  0.41234016,  0.10754603,\n",
            "         0.4373449 ,  0.37305456, -0.26067328, -0.39503515,  0.11681736],\n",
            "       [ 0.07204849,  0.4151563 , -0.05555546,  0.31070137, -0.26946104,\n",
            "        -0.365667  , -0.33725944, -0.4979413 ,  0.17689294,  0.17544776],\n",
            "       [-0.4803525 ,  0.50729835,  0.43630648,  0.45001394, -0.46468973,\n",
            "        -0.2749782 ,  0.314745  , -0.5120021 , -0.36219573,  0.15537465],\n",
            "       [-0.4784894 ,  0.33333987,  0.37089372,  0.5294893 ,  0.09190089,\n",
            "        -0.14041054, -0.32334822,  0.10266691,  0.54298306, -0.36130524],\n",
            "       [ 0.05223674, -0.2916999 ,  0.32731926,  0.22316599, -0.3457839 ,\n",
            "         0.04429531, -0.22043335,  0.0330233 , -0.17084873,  0.10079193],\n",
            "       [ 0.0284816 , -0.07293558, -0.23492682,  0.08706969,  0.11153746,\n",
            "         0.29859698,  0.3230241 , -0.49391934,  0.09820354, -0.26061046],\n",
            "       [ 0.15530908, -0.29608384, -0.31108153, -0.03395778, -0.15595224,\n",
            "         0.31363934,  0.12905025,  0.43931115,  0.11648762,  0.14713186],\n",
            "       [ 0.39354295, -0.14678699, -0.09627151,  0.20148867, -0.39138496,\n",
            "        -0.2970003 ,  0.0483942 ,  0.16986918, -0.31196168, -0.31889415],\n",
            "       [ 0.20475423,  0.5316272 , -0.08608991,  0.18729907, -0.37257975,\n",
            "        -0.37089205,  0.2999035 ,  0.11785275,  0.15123832, -0.23699716],\n",
            "       [-0.26673344, -0.38892078, -0.38496426,  0.29432118, -0.5095763 ,\n",
            "        -0.46422967, -0.22866714,  0.30114055,  0.2634321 , -0.5002002 ]],\n",
            "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([[ 0.3268671 , -0.20861784,  0.03140825, -0.11277598,  0.43636715,\n",
            "        -0.07329643,  0.14955276,  0.27063388],\n",
            "       [-0.07385117, -0.13695326,  0.22941124, -0.09423134, -0.01907992,\n",
            "        -0.494814  , -0.1769979 , -0.31630582],\n",
            "       [ 0.33266288, -0.44897416,  0.25293487,  0.06887573, -0.07132387,\n",
            "         0.57377887,  0.01909935,  0.35852504],\n",
            "       [-0.1835297 , -0.12046102,  0.5120157 , -0.5524647 , -0.16470441,\n",
            "        -0.11028409, -0.2815261 ,  0.16517204],\n",
            "       [-0.57039905, -0.40974486, -0.28959712,  0.55052435, -0.08304816,\n",
            "         0.2533543 , -0.30739388,  0.17752248],\n",
            "       [-0.31842977, -0.01740938,  0.01190436, -0.2048648 ,  0.10370314,\n",
            "         0.49343324,  0.04984689, -0.3871928 ],\n",
            "       [-0.20534602, -0.32274967, -0.29159224, -0.14602187, -0.53248954,\n",
            "        -0.56211764, -0.28997484, -0.4467525 ],\n",
            "       [ 0.3034923 ,  0.49970746,  0.05809385, -0.5258078 ,  0.06423843,\n",
            "        -0.23889667,  0.09041083,  0.4218434 ],\n",
            "       [-0.39708084,  0.32147765, -0.17661947, -0.18545076, -0.3494676 ,\n",
            "         0.16438287,  0.55825007,  0.48305213],\n",
            "       [ 0.5587311 , -0.36375812,  0.14222598,  0.559592  , -0.13617018,\n",
            "         0.17158669,  0.2731558 , -0.48209453]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "#model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "model.compile(loss='mse', optimizer='adam',metrics=['accuracy'])\n",
        "weight1 = model.get_weights()\n",
        "print(\"weight1\")\n",
        "print(weight1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDYql-F7YGYA"
      },
      "source": [
        "Comparing the data and writing into the file ( **input_output_predict.txt**)\n",
        "\n",
        "Here the\n",
        "*  **x_text** is the input sample data\n",
        "*  **y_text** is the expected output data\n",
        "*  **y_predict** is predicted output data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "F2j6Ej2ClAiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e60506c-fc07-4e69-d32b-09887f33e754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/180\n",
            "228/228 [==============================] - 2s 3ms/step - loss: 0.2308 - accuracy: 0.1756\n",
            "Epoch 2/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.1075 - accuracy: 0.2488\n",
            "Epoch 3/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0231 - accuracy: 0.2487\n",
            "Epoch 4/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.2490\n",
            "Epoch 5/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.2492\n",
            "Epoch 6/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 0.2492\n",
            "Epoch 7/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 0.2494\n",
            "Epoch 8/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 7.8239e-04 - accuracy: 0.2494\n",
            "Epoch 9/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.3387e-04 - accuracy: 0.2494\n",
            "Epoch 10/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.4841e-04 - accuracy: 0.2494\n",
            "Epoch 11/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.8154e-04 - accuracy: 0.2494\n",
            "Epoch 12/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.3889e-04 - accuracy: 0.4495\n",
            "Epoch 13/180\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 4.0889e-04 - accuracy: 0.4984\n",
            "Epoch 14/180\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 3.8592e-04 - accuracy: 0.4984\n",
            "Epoch 15/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 3.6518e-04 - accuracy: 0.4984\n",
            "Epoch 16/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.4615e-04 - accuracy: 0.4985\n",
            "Epoch 17/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.2811e-04 - accuracy: 0.4985\n",
            "Epoch 18/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.0980e-04 - accuracy: 0.4985\n",
            "Epoch 19/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.9176e-04 - accuracy: 0.6896\n",
            "Epoch 20/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.7204e-04 - accuracy: 0.7479\n",
            "Epoch 21/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.5798e-04 - accuracy: 0.7480\n",
            "Epoch 22/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.3953e-04 - accuracy: 0.7481\n",
            "Epoch 23/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.1980e-04 - accuracy: 0.7483\n",
            "Epoch 24/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.0581e-04 - accuracy: 0.8089\n",
            "Epoch 25/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.8867e-04 - accuracy: 0.7484\n",
            "Epoch 26/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.7282e-04 - accuracy: 0.9771\n",
            "Epoch 27/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.5907e-04 - accuracy: 0.8732\n",
            "Epoch 28/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.4815e-04 - accuracy: 1.0000\n",
            "Epoch 29/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.3786e-04 - accuracy: 0.9999\n",
            "Epoch 30/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 1.2865e-04 - accuracy: 0.9689\n",
            "Epoch 31/180\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 1.2096e-04 - accuracy: 0.8406\n",
            "Epoch 32/180\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 1.1474e-04 - accuracy: 0.8574\n",
            "Epoch 33/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.0784e-04 - accuracy: 0.9999\n",
            "Epoch 34/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.0149e-04 - accuracy: 0.9999\n",
            "Epoch 35/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 9.5699e-05 - accuracy: 0.8854\n",
            "Epoch 36/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 9.0999e-05 - accuracy: 0.9999\n",
            "Epoch 37/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.6022e-05 - accuracy: 0.9999\n",
            "Epoch 38/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.2634e-05 - accuracy: 0.9997\n",
            "Epoch 39/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 7.7072e-05 - accuracy: 0.9997\n",
            "Epoch 40/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 7.3666e-05 - accuracy: 0.9480\n",
            "Epoch 41/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.9368e-05 - accuracy: 0.9999\n",
            "Epoch 42/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.9911e-05 - accuracy: 0.9997\n",
            "Epoch 43/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.3247e-05 - accuracy: 0.9997\n",
            "Epoch 44/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.1391e-05 - accuracy: 0.9999\n",
            "Epoch 45/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.8174e-05 - accuracy: 0.9997\n",
            "Epoch 46/180\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 5.4065e-05 - accuracy: 0.9997\n",
            "Epoch 47/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 5.1625e-05 - accuracy: 0.9999\n",
            "Epoch 48/180\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 5.0664e-05 - accuracy: 0.9997\n",
            "Epoch 49/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.6135e-05 - accuracy: 0.9997\n",
            "Epoch 50/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.7436e-05 - accuracy: 0.9999\n",
            "Epoch 51/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.3356e-05 - accuracy: 0.9999\n",
            "Epoch 52/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.2310e-05 - accuracy: 0.9997\n",
            "Epoch 53/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.8551e-05 - accuracy: 0.9997\n",
            "Epoch 54/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.0561e-05 - accuracy: 0.9999\n",
            "Epoch 55/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.4603e-05 - accuracy: 0.9999\n",
            "Epoch 56/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.3000e-05 - accuracy: 0.9997\n",
            "Epoch 57/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.0840e-05 - accuracy: 0.9999\n",
            "Epoch 58/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.1512e-05 - accuracy: 0.9918\n",
            "Epoch 59/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.2492e-05 - accuracy: 1.0000\n",
            "Epoch 60/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.7896e-05 - accuracy: 0.9997\n",
            "Epoch 61/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.5401e-05 - accuracy: 0.9997\n",
            "Epoch 62/180\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 2.5443e-05 - accuracy: 0.9997\n",
            "Epoch 63/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 2.5346e-05 - accuracy: 0.9999\n",
            "Epoch 64/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 2.2521e-05 - accuracy: 0.8460\n",
            "Epoch 65/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.1854e-05 - accuracy: 0.9999\n",
            "Epoch 66/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.9941e-05 - accuracy: 0.9391\n",
            "Epoch 67/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.8900e-05 - accuracy: 0.9997\n",
            "Epoch 68/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.0015e-05 - accuracy: 0.9997\n",
            "Epoch 69/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.6920e-05 - accuracy: 0.8615\n",
            "Epoch 70/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.7631e-05 - accuracy: 0.9571\n",
            "Epoch 71/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.6127e-05 - accuracy: 0.9416\n",
            "Epoch 72/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.7944e-05 - accuracy: 1.0000\n",
            "Epoch 73/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.6025e-05 - accuracy: 0.9997\n",
            "Epoch 74/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.3595e-05 - accuracy: 0.8600\n",
            "Epoch 75/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.2477e-05 - accuracy: 0.9997\n",
            "Epoch 76/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.1853e-05 - accuracy: 0.9997\n",
            "Epoch 77/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.1134e-05 - accuracy: 0.8848\n",
            "Epoch 78/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.2073e-05 - accuracy: 0.8836\n",
            "Epoch 79/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 1.1312e-05 - accuracy: 0.9997\n",
            "Epoch 80/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 1.0294e-05 - accuracy: 0.9999\n",
            "Epoch 81/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.0001e-05 - accuracy: 0.9800\n",
            "Epoch 82/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.9512e-06 - accuracy: 0.9999\n",
            "Epoch 83/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.7882e-06 - accuracy: 1.0000\n",
            "Epoch 84/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.9499e-06 - accuracy: 0.9997\n",
            "Epoch 85/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 7.4733e-06 - accuracy: 0.9999\n",
            "Epoch 86/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 7.0073e-06 - accuracy: 0.9997\n",
            "Epoch 87/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.3629e-06 - accuracy: 0.9557\n",
            "Epoch 88/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.0389e-06 - accuracy: 0.9999\n",
            "Epoch 89/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.5914e-06 - accuracy: 0.9997\n",
            "Epoch 90/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.6636e-06 - accuracy: 1.0000\n",
            "Epoch 91/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.5071e-06 - accuracy: 0.9435\n",
            "Epoch 92/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.2272e-06 - accuracy: 0.9999\n",
            "Epoch 93/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 9.3847e-06 - accuracy: 0.9997\n",
            "Epoch 94/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.7458e-06 - accuracy: 0.9997\n",
            "Epoch 95/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 3.5638e-06 - accuracy: 0.9999\n",
            "Epoch 96/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 3.3672e-06 - accuracy: 0.9999\n",
            "Epoch 97/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.3034e-06 - accuracy: 0.9947\n",
            "Epoch 98/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.0573e-06 - accuracy: 0.9997\n",
            "Epoch 99/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.7932e-06 - accuracy: 0.9999\n",
            "Epoch 100/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.9951e-06 - accuracy: 0.9719\n",
            "Epoch 101/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.7612e-06 - accuracy: 0.9021\n",
            "Epoch 102/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.0808e-06 - accuracy: 0.9959\n",
            "Epoch 103/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.2174e-06 - accuracy: 0.7843\n",
            "Epoch 104/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.2782e-06 - accuracy: 0.8288\n",
            "Epoch 105/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.3267e-06 - accuracy: 0.7795\n",
            "Epoch 106/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.6025e-06 - accuracy: 0.8016\n",
            "Epoch 107/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.7514e-06 - accuracy: 0.8478\n",
            "Epoch 108/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.6680e-06 - accuracy: 0.7679\n",
            "Epoch 109/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.5720e-06 - accuracy: 0.7823\n",
            "Epoch 110/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.4287e-06 - accuracy: 0.7650\n",
            "Epoch 111/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 1.3280e-06 - accuracy: 0.7512\n",
            "Epoch 112/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 1.2789e-06 - accuracy: 0.7775\n",
            "Epoch 113/180\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 1.3989e-06 - accuracy: 0.7513\n",
            "Epoch 114/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.1779e-06 - accuracy: 0.8079\n",
            "Epoch 115/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 9.9579e-07 - accuracy: 0.8052\n",
            "Epoch 116/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.0202e-06 - accuracy: 0.7512\n",
            "Epoch 117/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.0905e-06 - accuracy: 0.7514\n",
            "Epoch 118/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.4175e-06 - accuracy: 0.9760\n",
            "Epoch 119/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.3387e-07 - accuracy: 0.9997\n",
            "Epoch 120/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.8697e-07 - accuracy: 0.9999\n",
            "Epoch 121/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 7.2828e-07 - accuracy: 0.9997\n",
            "Epoch 122/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.7756e-07 - accuracy: 0.9999\n",
            "Epoch 123/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.3929e-07 - accuracy: 0.8608\n",
            "Epoch 124/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.9100e-07 - accuracy: 0.7676\n",
            "Epoch 125/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.9399e-07 - accuracy: 0.9293\n",
            "Epoch 126/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.4588e-07 - accuracy: 0.7956\n",
            "Epoch 127/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 5.2007e-07 - accuracy: 0.8729\n",
            "Epoch 128/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 4.2789e-07 - accuracy: 0.8511\n",
            "Epoch 129/180\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 3.6401e-07 - accuracy: 0.7512\n",
            "Epoch 130/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.4053e-07 - accuracy: 0.7513\n",
            "Epoch 131/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.4085e-07 - accuracy: 0.7512\n",
            "Epoch 132/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.0021e-07 - accuracy: 0.8699\n",
            "Epoch 133/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.7351e-07 - accuracy: 0.7512\n",
            "Epoch 134/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.5778e-07 - accuracy: 0.7514\n",
            "Epoch 135/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.6974e-07 - accuracy: 0.7513\n",
            "Epoch 136/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.4808e-07 - accuracy: 0.8297\n",
            "Epoch 137/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.1458e-07 - accuracy: 0.8074\n",
            "Epoch 138/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.9419e-07 - accuracy: 0.8543\n",
            "Epoch 139/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.7180e-07 - accuracy: 0.7512\n",
            "Epoch 140/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.5513e-07 - accuracy: 0.7513\n",
            "Epoch 141/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.5534e-07 - accuracy: 0.7513\n",
            "Epoch 142/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.4415e-07 - accuracy: 0.7512\n",
            "Epoch 143/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 1.3605e-07 - accuracy: 0.8539\n",
            "Epoch 144/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 1.1960e-07 - accuracy: 0.7513\n",
            "Epoch 145/180\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 1.1732e-07 - accuracy: 0.7513\n",
            "Epoch 146/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.0217e-07 - accuracy: 0.7513\n",
            "Epoch 147/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 9.5455e-08 - accuracy: 0.7512\n",
            "Epoch 148/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 9.5690e-08 - accuracy: 0.7514\n",
            "Epoch 149/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.0565e-07 - accuracy: 0.7512\n",
            "Epoch 150/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.6633e-07 - accuracy: 0.8034\n",
            "Epoch 151/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.0044e-07 - accuracy: 0.8822\n",
            "Epoch 152/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.2771e-07 - accuracy: 0.9676\n",
            "Epoch 153/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 7.5493e-08 - accuracy: 0.7605\n",
            "Epoch 154/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 6.9634e-08 - accuracy: 0.8922\n",
            "Epoch 155/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.1447e-08 - accuracy: 0.8111\n",
            "Epoch 156/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 5.5950e-08 - accuracy: 0.8157\n",
            "Epoch 157/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.4950e-08 - accuracy: 0.7512\n",
            "Epoch 158/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.4672e-08 - accuracy: 0.8120\n",
            "Epoch 159/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 3.9078e-08 - accuracy: 0.7513\n",
            "Epoch 160/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 3.8443e-08 - accuracy: 0.7780\n",
            "Epoch 161/180\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 3.4983e-08 - accuracy: 0.7513\n",
            "Epoch 162/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.6121e-08 - accuracy: 0.8311\n",
            "Epoch 163/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.2983e-08 - accuracy: 0.8159\n",
            "Epoch 164/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 3.5145e-08 - accuracy: 0.8164\n",
            "Epoch 165/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.7036e-08 - accuracy: 0.7513\n",
            "Epoch 166/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.6850e-08 - accuracy: 0.7513\n",
            "Epoch 167/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.6158e-08 - accuracy: 0.8436\n",
            "Epoch 168/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.7836e-08 - accuracy: 0.8135\n",
            "Epoch 169/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.3605e-08 - accuracy: 0.9088\n",
            "Epoch 170/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.2339e-08 - accuracy: 0.9697\n",
            "Epoch 171/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 2.1143e-08 - accuracy: 0.8412\n",
            "Epoch 172/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.8532e-08 - accuracy: 0.9718\n",
            "Epoch 173/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.6989e-08 - accuracy: 0.8918\n",
            "Epoch 174/180\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 2.9914e-08 - accuracy: 0.9177\n",
            "Epoch 175/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 2.0546e-08 - accuracy: 0.7512\n",
            "Epoch 176/180\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 2.7490e-08 - accuracy: 0.8998\n",
            "Epoch 177/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.9599e-08 - accuracy: 0.9298\n",
            "Epoch 178/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 8.9571e-08 - accuracy: 0.9999\n",
            "Epoch 179/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 4.6863e-08 - accuracy: 0.9997\n",
            "Epoch 180/180\n",
            "228/228 [==============================] - 1s 3ms/step - loss: 1.1213e-08 - accuracy: 0.9997\n",
            "weight2\n",
            "[array([[-3.705794  , -1.3383827 , -1.6769369 ,  0.1655873 , -0.533273  ,\n",
            "         1.9071844 ,  2.4564798 ,  1.5699532 , -2.319662  ,  0.7044096 ],\n",
            "       [ 0.7922774 ,  0.25081375,  0.6490961 ,  1.9241776 , -0.11877275,\n",
            "        -0.5826611 ,  1.2750298 ,  0.31354368,  0.22708315,  0.77745724],\n",
            "       [-0.67548066,  0.37471026,  0.68482715,  0.00894311, -0.42998526,\n",
            "         1.0145897 , -0.26214904, -0.3036736 ,  1.0898575 , -0.23688735],\n",
            "       [ 1.1214812 ,  0.3907727 ,  0.52755624,  0.11841469,  0.19967525,\n",
            "        -0.43769795,  0.45962894,  0.7898648 , -0.8293534 ,  1.1189004 ],\n",
            "       [-0.27078676,  0.90368754, -0.52748233,  0.22390297, -0.41843298,\n",
            "         0.30958506, -0.2372702 , -0.30520317,  0.6764368 , -0.9223882 ],\n",
            "       [ 0.6542044 ,  0.9335957 , -0.3972199 , -0.82583356, -0.27558726,\n",
            "        -0.27967262,  0.16071697,  0.5937165 , -0.5894579 ,  0.5942422 ],\n",
            "       [ 0.40920025,  1.4300922 , -0.6597327 , -0.34076932,  0.01346785,\n",
            "         0.34927732,  0.3578099 , -0.57426   ,  0.4721845 , -0.16785096],\n",
            "       [ 0.72412455,  0.02256338,  0.5163469 , -0.46186936, -0.5032913 ,\n",
            "        -0.68288434,  1.0807507 ,  0.5903263 ,  0.3767931 , -0.7730521 ],\n",
            "       [-0.42210928,  1.2073442 , -0.58529484, -1.3962129 ,  0.42320347,\n",
            "        -0.39306623, -0.05315409, -1.5177518 , -0.48040396,  0.13250665],\n",
            "       [-0.16239853,  0.5965868 , -0.5475436 , -2.2198336 ,  0.47876668,\n",
            "        -0.67938733,  1.5418209 ,  0.69255483,  0.18099251, -2.0396714 ]],\n",
            "      dtype=float32), array([ 0.6173325 ,  0.11999721,  0.85881424,  1.343714  , -0.08900844,\n",
            "        0.16539823,  0.8513945 ,  0.22501694,  0.5276247 ,  0.42303807],\n",
            "      dtype=float32), array([[-2.1695838 , -0.39937943, -0.5560466 , -1.0239152 ,  0.10754603,\n",
            "         3.0038102 ,  2.0760443 , -1.687587  , -0.79468656,  0.01270295],\n",
            "       [ 0.67313474,  1.6418326 , -0.12870957,  0.91269684, -0.25757006,\n",
            "         0.08368763, -1.1025851 , -1.8025844 ,  0.5315233 ,  0.09477741],\n",
            "       [-1.3818849 ,  0.7955257 ,  1.0813259 ,  0.7908279 , -0.46468973,\n",
            "         1.6546928 ,  2.1889873 , -2.012603  , -1.6815734 ,  0.08381674],\n",
            "       [-0.5403912 ,  1.1242491 ,  0.6364496 ,  1.8135754 ,  0.09190089,\n",
            "        -0.41324377,  1.0828211 ,  0.6509755 ,  0.4316529 , -0.36130524],\n",
            "       [ 0.05223674, -0.20885919,  0.32731926,  0.3100045 , -0.3457839 ,\n",
            "         0.01408093, -0.22043335,  0.0330233 , -0.17084873,  0.10079193],\n",
            "       [-0.98575   , -0.4720058 ,  0.10893989, -0.52494746,  0.11805296,\n",
            "         1.6150324 ,  2.373177  , -0.02059827,  0.8845969 , -0.26061046],\n",
            "       [ 0.6932006 , -1.0495294 , -0.54005927, -0.31580058, -0.13383305,\n",
            "         1.0891036 ,  0.634172  ,  1.419551  ,  0.5633043 ,  0.04477033],\n",
            "       [ 1.4548604 , -0.60646695, -0.40290818,  0.50512296, -0.39454633,\n",
            "        -1.035586  ,  0.27153623,  1.641426  , -1.2898952 , -0.3849936 ],\n",
            "       [ 1.7087162 ,  2.164715  ,  0.8866596 ,  2.006749  , -0.38680178,\n",
            "        -1.5852578 , -0.16616724, -1.5972357 , -0.44157007, -0.23699716],\n",
            "       [ 0.3178849 , -0.34812996, -0.6619337 ,  1.8886361 , -0.5095763 ,\n",
            "        -0.8458143 ,  0.15881969,  1.5673261 , -0.18520163, -0.5002002 ]],\n",
            "      dtype=float32), array([ 0.37497556,  0.48762643,  0.45899278,  0.291889  ,  0.00565873,\n",
            "        0.5790879 ,  0.848474  ,  0.51008075, -0.21275839, -0.07834908],\n",
            "      dtype=float32), array([[ 0.72535974, -1.6033779 ,  1.0587815 , -1.2674896 ,  1.622492  ,\n",
            "        -0.558389  ,  1.568284  , -1.6419257 ],\n",
            "       [ 1.251528  , -1.3064787 ,  0.9015233 , -1.4701821 ,  0.7330368 ,\n",
            "        -1.6502197 ,  0.36011234, -1.6291094 ],\n",
            "       [ 0.9712785 , -1.556039  ,  0.09958937, -0.16251478, -0.49420422,\n",
            "         0.25913215, -0.6783081 ,  0.2928112 ],\n",
            "       [ 1.044283  , -1.0894514 ,  0.76846564, -1.9231527 ,  0.14813323,\n",
            "        -0.6890163 , -0.375408  , -1.9412161 ],\n",
            "       [-0.5973976 , -0.37972668, -0.3177401 ,  0.5578792 , -0.11057059,\n",
            "         0.22127436, -0.33679935,  0.1448954 ],\n",
            "       [-1.9053992 ,  1.2829801 , -1.754485  ,  0.9709295 , -1.4475311 ,\n",
            "         1.1636951 , -1.2429456 ,  0.8530216 ],\n",
            "       [-1.1636283 ,  0.62379193, -1.5091292 ,  0.57984567, -1.8788943 ,\n",
            "        -0.2244146 , -2.7079053 , -0.33381397],\n",
            "       [ 0.85586876, -0.89556926,  0.7064789 , -1.5938126 ,  0.49193326,\n",
            "        -1.9204103 ,  0.64449286, -2.228739  ],\n",
            "       [-0.32081246,  1.3020414 , -1.9827824 ,  1.395477  , -0.03522702,\n",
            "         1.3322835 ,  0.45065024,  0.9890364 ],\n",
            "       [ 0.5359659 , -0.33686626,  0.11610368,  0.5866812 , -0.16319057,\n",
            "         0.19253753,  0.24662958, -0.4483915 ]], dtype=float32), array([-0.1670492 , -0.13335949, -0.478422  ,  0.28178307, -0.45685002,\n",
            "       -0.33640778, -0.6383085 , -0.29470497], dtype=float32)]\n",
            "98/98 - 0s - loss: 7.9410e-05 - accuracy: 1.0000 - 285ms/epoch - 3ms/step\n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=180)\n",
        "weight2 = model.get_weights()\n",
        "print(\"weight2\")\n",
        "print(weight2)\n",
        "weight_l1 = model.layers[0].get_weights()[0]\n",
        "weight_l1_b = model.layers[0].get_weights()[1]\n",
        "weight_l2 = model.layers[1].get_weights()[0]\n",
        "weight_l2_b = model.layers[1].get_weights()[1]\n",
        "weight_l3 = model.layers[2].get_weights()[0]\n",
        "weight_l3_b = model.layers[2].get_weights()[1]\n",
        "f1 = open(\"ann_weight_shift8.txt\", \"w\")\n",
        "f1.write(\"#layers\"+\"\\n\"+str(layers)+\"\\n\")\n",
        "f1.write(\"#inputs\"+\"\\n\"+str(inputs)+\"\\n\")\n",
        "f1.write(\"#neurons_L1\"+\"\\n\"+str(neurons_l0)+\"\\n\")\n",
        "f1.write(\"#neurons_L2\"+\"\\n\"+str(neurons_l1)+\"\\n\")\n",
        "f1.write(\"#neurons_L3\"+\"\\n\"+str(neurons_l2)+\"\\n\")\n",
        "\n",
        "f1.write(\"#L1_wt\"+\"\\n\")\n",
        "for i in range(0,10):\n",
        "  f1.write(str(weight_l1[i][0])+\"\\b\"+str(weight_l1[i][1])+\"\\b\"+str(weight_l1[i][2])+\"\\b\"+str(weight_l1[i][3])+\"\\b\"+str(weight_l1[i][4])+\"\\b\"+str(weight_l1[i][5])+\"\\b\"+str(weight_l1[i][6])+\"\\b\"+str(weight_l1[i][7])+\"\\b\"+str(weight_l1[i][8])+\"\\b\"+str(weight_l1[i][9])+\"\\n\")\n",
        "\n",
        "\n",
        "f1.write(\"#L1_b\"+\"\\n\")\n",
        "#for i in range(0,10):\n",
        " #   f1.write(str(weight_l1_b[i])+\"\\b\")\n",
        "#f1.write(\"\\n\")\n",
        "f1.write(str(weight_l1_b[0])+\"\\b\"+str(weight_l1_b[1])+\"\\b\"+str(weight_l1_b[2])+\"\\b\"+str(weight_l1_b[3])+\"\\b\"+str(weight_l1_b[4])+\"\\b\"+str(weight_l1_b[5])+\"\\b\"+str(weight_l1_b[6])+\"\\b\"+str(weight_l1_b[7])+\"\\b\"+str(weight_l1_b[8])+\"\\b\"+str(weight_l1_b[9])+\"\\n\")\n",
        "\n",
        "f1.write(\"#L2_wt\"+\"\\n\")\n",
        "for i in range(0,10):\n",
        "  f1.write(str(weight_l2[i][0])+\"\\b\"+str(weight_l2[i][1])+\"\\b\"+str(weight_l2[i][2])+\"\\b\"+str(weight_l2[i][3])+\"\\b\"+str(weight_l2[i][4])+\"\\b\"+str(weight_l2[i][5])+\"\\b\"+str(weight_l2[i][6])+\"\\b\"+str(weight_l2[i][7])+\"\\b\"+str(weight_l2[i][8])+\"\\b\"+str(weight_l2[i][9])+\"\\n\")\n",
        "'''\n",
        "  for j in range(0,10):\n",
        "    f1.write(str(weight_l2[i][j])+\"\\b\")\n",
        "  f1.write(\"\\n\")\n",
        "'''\n",
        "\n",
        "\n",
        "f1.write(\"#L2_b\"+\"\\n\")\n",
        "'''\n",
        "for i in range(0,10):\n",
        "  f1.write(str(weight_l2_b[i])+\"\\b\")\n",
        "f1.write(\"\\n\")\n",
        "'''\n",
        "f1.write(str(weight_l2_b[0])+\"\\b\"+str(weight_l2_b[1])+\"\\b\"+str(weight_l2_b[2])+\"\\b\"+str(weight_l2_b[3])+\"\\b\"+str(weight_l2_b[4])+\"\\b\"+str(weight_l2_b[5])+\"\\b\"+str(weight_l2_b[6])+\"\\b\"+str(weight_l2_b[7])+\"\\b\"+str(weight_l2_b[8])+\"\\b\"+str(weight_l2_b[9])+\"\\n\")\n",
        "\n",
        "f1.write(\"#L3_wt\"+\"\\n\")\n",
        "for i in range(0,10):\n",
        "  f1.write(str(weight_l3[i][0])+\"\\b\"+str(weight_l3[i][1])+\"\\b\"+str(weight_l3[i][2])+\"\\b\"+str(weight_l3[i][3])+\"\\b\"+str(weight_l3[i][4])+\"\\b\"+str(weight_l3[i][5])+\"\\b\"+str(weight_l3[i][6])+\"\\b\"+str(weight_l3[i][7])+\"\\n\")\n",
        "#  for j in range(0,8):\n",
        "#    f1.write(str(weight_l3[i][j])+\"\\b\")\n",
        "#  f1.write(\"\\n\")\n",
        "\n",
        "\n",
        "f1.write(\"#L3_b\"+\"\\n\")\n",
        "#for i in range(0,8):\n",
        "#  f1.write(str(weight_l3_b[i])+\"\\b\")\n",
        "#f1.write(\"\\n\")\n",
        "f1.write(str(weight_l3_b[0])+\"\\b\"+str(weight_l3_b[1])+\"\\b\"+str(weight_l3_b[2])+\"\\b\"+str(weight_l3_b[3])+\"\\b\"+str(weight_l3_b[4])+\"\\b\"+str(weight_l3_b[5])+\"\\b\"+str(weight_l3_b[6])+\"\\b\"+str(weight_l3_b[7])+\"\\n\")\n",
        "\n",
        "f1.write(\"#end\\n#end\\n\")\n",
        "\n",
        "f1.close()\n",
        "########\n",
        "score = model.evaluate(x_test, y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "lznry1JxVlab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2588c1e6-7376-4a1c-aba4-1e761d5b4470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 0s 1ms/step\n",
            "[0 1 0 1 0 1 0 1 0 1]   [0 1 0 1 0 1 0 1]   [0. 1. 0. 1. 0. 1. 0. 1.]\n",
            "\n",
            "\n",
            "[0 0 1 0 1 0 1 0 1 0]   [1 0 1 0 1 0 1 0]   [1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "\n",
            "\n",
            "[0 1 0 1 0 1 0 1 0 1]   [0 1 0 1 0 1 0 1]   [0. 1. 0. 1. 0. 1. 0. 1.]\n",
            "\n",
            "\n",
            "[1 0 1 0 1 0 1 0 1 0]   [0 1 0 1 0 1 0 1]   [0. 1. 0. 1. 0. 1. 0. 1.]\n",
            "\n",
            "\n",
            "[1 0 1 0 1 0 1 0 1 0]   [0 1 0 1 0 1 0 1]   [0. 1. 0. 1. 0. 1. 0. 1.]\n",
            "\n",
            "\n",
            "[1 0 1 0 1 0 1 0 1 0]   [0 1 0 1 0 1 0 1]   [0. 1. 0. 1. 0. 1. 0. 1.]\n",
            "\n",
            "\n",
            "[0 0 1 0 1 0 1 0 1 0]   [1 0 1 0 1 0 1 0]   [1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "\n",
            "\n",
            "[0 0 1 0 1 0 1 0 1 0]   [1 0 1 0 1 0 1 0]   [1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "\n",
            "\n",
            "[0 0 1 0 1 0 1 0 1 0]   [1 0 1 0 1 0 1 0]   [1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "\n",
            "\n",
            "[0 1 0 1 0 1 0 1 0 1]   [0 1 0 1 0 1 0 1]   [0. 1. 0. 1. 0. 1. 0. 1.]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Comparing the data and writing into the file ( input_output_predict.txt)\n",
        "y_predict = model.predict(x_test).round()\n",
        "\n",
        "for i in range(10,20):\n",
        "  print(x_test[i],\" \",y_test[i],\" \",y_predict[i])\n",
        "  print(\"\\n\")\n",
        "# f = open(\"input_output_predict.txt\", \"w\")\n",
        "# n = y_test.size\n",
        "# cnt = 0\n",
        "# for i in range(0,n-1):\n",
        "#     # f.write(\"[\")\n",
        "#     # count = 0\n",
        "#     # for x in x_test[i]:\n",
        "#     #     for j in x:\n",
        "#     #       f.write(str(j)+\",\")\n",
        "#     # f.write(\"];\\t\")\n",
        "#     # f.write(\"[\"+str(y_test[i])+\"];\\t\")\n",
        "#     # f.write(\"[\"+str(y_predict[i])+\"];\\t \\n\")\n",
        "#     ok=1\n",
        "#     # print(\"hi\")\n",
        "#     # print(len(y_test[i]))\n",
        "#     for  y,y_ex in zip(y_test[i],y_predict[i]):\n",
        "#       if y!=y_ex:\n",
        "#         ok=0\n",
        "#     cnt+=ok\n",
        "# f.write(\"Number of matches: \"+str(cnt)+\" out of \" + str(n) +\"\\n\")\n",
        "# f.close()\n",
        "# print(\"Number of matches: \"+str(cnt)+\" out of \" + str(n) )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YEo9vneC1RiB"
      },
      "execution_count": 24,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}